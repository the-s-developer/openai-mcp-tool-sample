# Chat Loop with OpenAIÂ &Â MCP

## English ğŸ‡¬ğŸ‡§

### Overview

This project demonstrates how to build a **streaming, toolâ€‘enabled chat loop** that connects
OpenAIâ€™s GPTâ€‘4o (or GPTâ€‘4oâ€‘mini) with an **MCP (Multiâ€‘Capability Platform)** server. The script
creates an asynchronous conversation where the assistant can call remote tools exposed by the
MCP, handle streaming responses, and display final answers once all tool calls are resolved.

### Features

* **Asynchronous**: Built on `asyncio`, `openai.AsyncOpenAI`, and an async MCP client.
* **Streaming completions**: See assistant responses as they generate.
* **Dynamic tool usage**: Discovers available MCP tools at runtime and lets the model invoke them.
* **Automatic argument assembly**: Collects partial toolâ€‘call deltas before executing the tool.

### Folder Structure

```
.
â”œâ”€â”€ chat_loop.py      # Main script (the code in this repository)
â””â”€â”€ README.md         # You are here
```

### Prerequisites

| Requirement | Version        |
| ----------- | -------------- |
| Python      | 3.10Â or higher |
| pip         | latest         |

Install dependencies:

```bash
pip install openai mcp
```

*(If your MCP client lives in a different package name, adjust accordingly.)*

### Starting a Local MCP Server (Playwright implementation)

If you donâ€™t already have an MCP server running, you can spin up a quick local instance powered by
[Playwright MCP](https://www.npmjs.com/package/@playwright/mcp):

```bash
npx @playwright/mcp@latest --port 8931
```

This will start an MCP server at `http://localhost:8931` and print something like:

```text
Listening on http://localhost:8931
Put this in your client config:
{
  "mcpServers": {
    "playwright": {
      "url": "http://localhost:8931/sse"
    }
  }
}
If your client supports streamable HTTP, you can use the /mcp endpoint instead.
```

*For the Python script in this repo, we use the streamableâ€‘HTTP endpoint (`/mcp`).*
If you change the port or host, remember to update `MCP_URL` in **chat\_loop.py**.

### Configuration

Set an **environment variable** for your OpenAI key or replace the placeholder string in the
script (not recommended for production):

```bash
export OPENAI_APIKEY="sk-...your-key..."
```

Ensure your MCP server is running locally at the default URL or set `MCP_URL`.

### Running the Script

```bash
python chat_loop.py "What's the weather like in Istanbul today?"
```

If no argument is provided, the script defaults to:

```text
What's the weather like in Istanbul today?
```

**Example interaction** (after starting the Playwright MCP server):

```bash
$ python chat_loop.py "Ä°stanbul'da hava durumu nedir?"

ğŸ’¬ Assistant: Ä°stanbul HavalimanÄ± iÃ§in hava durumu ÅŸu ÅŸekildedir:

- Durum: Ã‡ok Bulutlu
- SÄ±caklÄ±k: 14,6â€¯Â°C
- BasÄ±nÃ§: 1016â€¯hPa
- RÃ¼zgar: 31â€¯km/sa (KuzeydoÄŸudan)
- Nem: %63

Hava durumu 13Â MayÄ±sÂ 2025 tarihinde saatÂ 12:50 iÃ§in geÃ§erlidir.
```

### How It Works (High Level)

1. **Tool Discovery** â€“ `session.list_tools()` fetches tool metadata from the MCP server.
2. **OpenAI Chat Request** â€“ The assistant receives the user prompt + tool definitions.
3. **Streaming Response** â€“ As chunks arrive, the script collects normal text and any
   `tool_calls` emitted by the model.
4. **Tool Execution** â€“ Once a complete toolâ€‘call payload is assembled, the script invokes the
   corresponding MCP tool and appends the result to the chat history as a `tool` role message.
5. **Final Answer** â€“ When the assistant eventually responds without further tool calls, the loop
   prints the answer and exits.

### Customising

* **Model Choice**: Change `model="gpt-4o-mini"` to any model your key has access to.
* **MCP Endpoint**: Edit `MCP_URL` if your MCP server is on a different host or port.
* **System / Assistant Prompts**: Prepend system instructions or modify the user prompt list as
  needed.

### License

MITÂ â€“ feel free to adapt.

---

## TÃ¼rkÃ§e ğŸ‡¹ğŸ‡·

### Genel BakÄ±ÅŸ

Bu proje, OpenAIâ€™nin GPTâ€‘4o modelini **MCP (Multiâ€‘Capability Platform)** sunucusuna baÄŸlayarak
**akÄ±ÅŸ (streaming) destekli ve araÃ§ kullanabilen** bir sohbet dÃ¶ngÃ¼sÃ¼ kurmanÄ±n Ã¶rneÄŸini sunar.
Betik, asenkron olarak Ã§alÄ±ÅŸan bir sohbet oluÅŸturur; asistan MCPâ€™nin sunduÄŸu araÃ§larÄ±
Ã§aÄŸÄ±rabilir, akÄ±ÅŸ hÃ¢lindeki yanÄ±tlarÄ± yÃ¶netir ve tÃ¼m araÃ§ Ã§aÄŸrÄ±larÄ± tamamlanÄ±nca nihai yanÄ±tÄ±
Ã§Ä±ktÄ±lar.

### Ã–zellikler

* **Asenkron** yapÄ± (`asyncio`, `openai.AsyncOpenAI`, asenkron MCP istemcisi).
* **Streaming** tamamlamalar: YanÄ±tlar oluÅŸturulurken anlÄ±k gÃ¶rebilirsiniz.
* **Dinamik araÃ§ kullanÄ±mÄ±**: MCPâ€™nin saÄŸladÄ±ÄŸÄ± araÃ§lar Ã§alÄ±ÅŸma zamanÄ±nda keÅŸfedilir ve model
  tarafÄ±ndan Ã§aÄŸrÄ±lÄ±r.
* **Otomatik argÃ¼man birleÅŸtirme**: ParÃ§alÄ± `tool_call` deltalarÄ±nÄ± toplar ve tek seferde
  Ã§alÄ±ÅŸtÄ±rÄ±r.

### Dosya YapÄ±sÄ±

```
.
â”œâ”€â”€ chat_loop.py   # Ana betik
â””â”€â”€ README.md      # Bu dosya
```

### Gereksinimler

| Gereksinim | SÃ¼rÃ¼m  |
| ---------- | ------ |
| Python     | 3.10+  |
| pip        | gÃ¼ncel |

Kurulum:

```bash
pip install openai mcp
```

### Yerel MCP Sunucusunu BaÅŸlatma (Playwright sÃ¼rÃ¼mÃ¼)

HenÃ¼z MCP sunucunuz yoksa, [Playwright MCP](https://www.npmjs.com/package/@playwright/mcp)
ile hÄ±zlÄ±ca yerel bir Ã¶rnek baÅŸlatabilirsiniz:

```bash
npx @playwright/mcp@latest --port 8931
```

Bu komut `http://localhost:8931` adresinde bir MCP sunucusu baÅŸlatacak ve aÅŸaÄŸÄ±dakine benzer
Ã§Ä±ktÄ± Ã¼retecektir:

```text
Listening on http://localhost:8931
Put this in your client config:
{
  "mcpServers": {
    "playwright": {
      "url": "http://localhost:8931/sse"
    }
  }
}
If your client supports streamable HTTP, you can use the /mcp endpoint instead.
```

*Bu depodaki Python betiÄŸi `streamableâ€‘HTTP` yolu (`/mcp`) kullanÄ±r.*
BaÄŸlantÄ± noktasÄ± veya host deÄŸiÅŸtirirseniz, **chat\_loop.py** iÃ§indeki `MCP_URL` sabitini
uygulayÄ±n.

### YapÄ±landÄ±rma

AÅŸaÄŸÄ±dakilerden birini yapÄ±n:

1. Ortam deÄŸiÅŸkeni oluÅŸturun:

   ```bash
   export OPENAI_APIKEY="sk-...anahtarÄ±nÄ±z..."
   ```
2. Veya **geÃ§ici** olarak betikteki `OPENAI_APIKEY` sabitini deÄŸiÅŸtirin *(Ã¼retim iÃ§in tavsiye
   edilmez!)*.

`MCP_URL` deÄŸiÅŸkeni MCP sunucunuz farklÄ±ysa dÃ¼zenlenmelidir.

### Ã‡alÄ±ÅŸtÄ±rma

```bash
python chat_loop.py "Ä°stanbul'da hava durumu nedir?"
```

Parametre verilmezse betik ÅŸu varsayÄ±lan soruyu kullanÄ±r:

```text
Ä°stanbul'da hava durumu bugÃ¼n nasÄ±l?
```

**Ã–rnek etkileÅŸim** (Playwright MCP sunucusu baÅŸlatÄ±ldÄ±ktan sonra):

```bash
$ python chat_loop.py "Ä°stanbul'da hava durumu nedir?"

ğŸ’¬ Assistant: Ä°stanbul HavalimanÄ± iÃ§in hava durumu ÅŸu ÅŸekildedir:

- Durum: Ã‡ok Bulutlu
- SÄ±caklÄ±k: 14,6â€¯Â°C
- BasÄ±nÃ§: 1016â€¯hPa
- RÃ¼zgar: 31â€¯km/sa (KuzeydoÄŸudan)
- Nem: %63

Hava durumu 13Â MayÄ±sÂ 2025 tarihinde saatÂ 12:50 iÃ§in geÃ§erlidir.
```

### NasÄ±l Ã‡alÄ±ÅŸÄ±r (Ã–zet)

1. **AraÃ§ KeÅŸfi** â€“ `session.list_tools()` MCP Ã¼zerindeki araÃ§larÄ± alÄ±r.
2. **OpenAI Sohbet Ä°steÄŸi** â€“ Asistan, kullanÄ±cÄ± Ã¶nceden tanÄ±mlÄ± araÃ§ listesiyle birlikte
   isteÄŸi alÄ±r.
3. **AkÄ±ÅŸ YanÄ±tÄ±** â€“ ParÃ§alar geldikÃ§e normal metin ve `tool_calls` toplanÄ±r.
4. **AraÃ§ Ã‡alÄ±ÅŸtÄ±rma** â€“ Tam `tool_call` verisi oluÅŸtuÄŸunda ilgili MCP aracÄ± Ã§aÄŸrÄ±lÄ±r ve sonucu
   `tool` rolÃ¼nde sohbete eklenir.
5. **Final YanÄ±t** â€“ Asistan yeni araÃ§ Ã§aÄŸrÄ±sÄ± olmadan yanÄ±t verdiÄŸinde dÃ¶ngÃ¼ sonlanÄ±r.

### Ã–zelleÅŸtirme

* **Model SeÃ§imi**: `model="gpt-4o-mini"` deÄŸerini eriÅŸiminiz olan baÅŸka bir modele
  deÄŸiÅŸtirebilirsiniz.
* **MCP Adresi**: `MCP_URL`â€™yi sunucunuzun adresine gÃ¶re ayarlayÄ±n.
* **Sistem/Asistan Ä°letileri**: Gerekirse sistem talimatlarÄ± ekleyin veya ileti geÃ§miÅŸini
  dÃ¼zenleyin.

### Lisans

MIT â€“ dilediÄŸiniz gibi kullanÄ±n ve uyarlayÄ±n.
